{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "50125019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî® Tentando criar o banco de dados 'db_aviao'...\n",
      "O banco 'db_aviao' j√° existe (tudo certo).\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "print(\"üî® Tentando criar o banco de dados 'db_aviao'...\")\n",
    "\n",
    "# 1. Conecta no banco padr√£o 'postgres' (que sempre existe)\n",
    "# Nota: Usamos as credenciais 'admin'/'admin' que voc√™ definiu no docker-compose\n",
    "try:\n",
    "    con = psycopg2.connect(\n",
    "        user='admin', \n",
    "        password='admin', \n",
    "        host='localhost', \n",
    "        port=5432, \n",
    "        database='postgres' # Conecta no default para poder criar outros\n",
    "    )\n",
    "    \n",
    "    # Necess√°rio para criar banco de dados (n√£o pode estar em transa√ß√£o)\n",
    "    con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # 2. Tenta criar o banco novo\n",
    "    cur.execute(\"CREATE DATABASE db_aviao;\")\n",
    "    print(\"SUCESSO! Banco 'db_aviao' criado.\")\n",
    "    \n",
    "except psycopg2.errors.DuplicateDatabase:\n",
    "    print(\"O banco 'db_aviao' j√° existe (tudo certo).\")\n",
    "except Exception as e:\n",
    "    print(f\" Erro ao tentar criar banco: {e}\")\n",
    "finally:\n",
    "    if 'con' in locals(): con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "276a9f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ata\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ata\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\ata\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (2.0.45)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\ata\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (2.9.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ata\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ata\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ata\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\ata\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from sqlalchemy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\ata\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from sqlalchemy) (4.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ata\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy sqlalchemy psycopg2-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46948268",
   "metadata": {},
   "source": [
    "# ETL Bronze to Silver: Aviation Data\n",
    "\n",
    "Este notebook realiza o processamento da camada **Bronze (Raw)** para a **Silver (Trusted)**.\n",
    "O objetivo √© padronizar tipos de dados, limpar inconsist√™ncias observadas na an√°lise explorat√≥ria e enriquecer o dataset com novas features.\n",
    "\n",
    "**Pipeline:**\n",
    "1. Ingest√£o do CSV Bruto (`cp1252`).\n",
    "2. Limpeza e Padroniza√ß√£o de Colunas.\n",
    "3. Tratamento de Tipos (Datas, Inteiros, Booleanos).\n",
    "4. Engenharia de Atributos (Extra√ß√£o de Ano, M√™s, Categorias).\n",
    "5. Carga no Data Warehouse (PostgreSQL)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfa310e",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o e Importa√ß√µes\n",
    "Importa√ß√£o das bibliotecas essenciais para manipula√ß√£o de dados e conex√£o com banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8b0a9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from psycopg2.extras import execute_batch\n",
    "\n",
    "# Configura√ß√µes de exibi√ß√£o do Pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "46705ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diret√≥rio onde o script est√° rodando: c:\\Users\\ATA\\OneDrive\\Documentos\\Acidentes_aviao\\Transformer\n",
      "SUCESSO! Arquivo encontrado em: ../Data_Layer/raw/dados_brutos.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(f\"Diret√≥rio onde o script est√° rodando: {os.getcwd()}\")\n",
    "\n",
    "# O caminho exato baseado na estrutura de pastas\n",
    "# ../ volta para 'Acidentes_aviao'\n",
    "# Data_Layer entra na pasta (com underline)\n",
    "# raw/dados_brutos.csv √© o arquivo final\n",
    "INPUT_FILE = '../Data_Layer/raw/dados_brutos.csv'\n",
    "\n",
    "if os.path.exists(INPUT_FILE):\n",
    "    print(f\"SUCESSO! Arquivo encontrado em: {INPUT_FILE}\")\n",
    "else:\n",
    "    print(f\"AINDA N√ÉO ACHOU em: {INPUT_FILE}\")\n",
    "    # √öltima tentativa: verificar se por acaso n√£o est√° na mesma pasta\n",
    "    if os.path.exists('dados_brutos.csv'):\n",
    "        INPUT_FILE = 'dados_brutos.csv'\n",
    "        print(f\"Achou na mesma pasta!\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Verifique se o arquivo 'dados_brutos.csv' est√° mesmo dentro de 'Data_Layer/raw'\")\n",
    "\n",
    "# Configura√ß√£o do Banco de Dados\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'database': 'db_aviao',\n",
    "    'user': 'admin',\n",
    "    'password': 'admin'\n",
    "}\n",
    "\n",
    "DB_CONNECTION_STR = f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f37dc",
   "metadata": {},
   "source": [
    "## 2. Fun√ß√µes Auxiliares\n",
    "Desenvolvemos fun√ß√µes modulares para tratar problemas espec√≠ficos identificados na fase de Analytics, como caracteres especiais e normaliza√ß√£o de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f666b6c",
   "metadata": {},
   "source": [
    "### 2.1 Limpeza de Texto e Strings\n",
    "Fun√ß√£o para remover espa√ßos extras e caracteres estranhos dos nomes de cidades e modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e535c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Remove espa√ßos extras e normaliza caracteres.\n",
    "    Ex: ' Cessna  ' -> 'Cessna'\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Normaliza unicode (remove acentos se necess√°rio, aqui mantemos compatibilidade)\n",
    "    text_norm = unicodedata.normalize('NFKC', str(text)).strip()\n",
    "    return text_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357f372c",
   "metadata": {},
   "source": [
    "### 2.2 Tratamento de Severidade (Regra de Neg√≥cio)\n",
    "Padroniza√ß√£o da coluna `Injury.Severity`. Muitas vezes ela vem como \"Fatal(2)\" e queremos apenas separar a categoria do n√∫mero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cacd0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_severity(text):\n",
    "    \"\"\"\n",
    "    Ex: 'Fatal(2)' -> 'Fatal'\n",
    "    Ex: 'Non-Fatal' -> 'Non-Fatal'\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return 'Unavailable'\n",
    "    \n",
    "    text = str(text).strip()\n",
    "    if text.lower().startswith('fatal'):\n",
    "        return 'Fatal'\n",
    "    elif text.lower().startswith('non-fatal'):\n",
    "        return 'Non-Fatal'\n",
    "    elif text.lower().startswith('incident'):\n",
    "        return 'Incident'\n",
    "    \n",
    "    return 'Unavailable'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2a984c",
   "metadata": {},
   "source": [
    "## 3. Carregando os Dados Brutos\n",
    "Iniciamos o ETL lendo o arquivo CSV original. Tratamos o encoding `cp1252` que √© comum em arquivos antigos ou gerados por Excel/Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d0f309ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ETL BRONZE -> SILVER: AVIATION DATA\n",
      "================================================================================\n",
      "\n",
      "Carregando dados Bronze...\n",
      "   Carregado: 88,889 linhas x 31 colunas\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ETL BRONZE -> SILVER: AVIATION DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nCarregando dados Bronze...\")\n",
    "# Tratamento de erro de encoding observado na analytics\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE, encoding='cp1252', low_memory=False)\n",
    "except:\n",
    "    df = pd.read_csv(INPUT_FILE, encoding='latin-1', low_memory=False)\n",
    "\n",
    "print(f\"   Carregado: {df.shape[0]:,} linhas x {df.shape[1]} colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6aa716",
   "metadata": {},
   "source": [
    "## 4. Renomea√ß√£o e Sele√ß√£o de Colunas\n",
    "Padronizamos os nomes das colunas para `snake_case` (padr√£o de banco de dados) e selecionamos apenas as colunas definidas no Dicion√°rio de Dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "fb20b14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Renomeando colunas...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRenomeando colunas...\")\n",
    "\n",
    "# Mapa de De-Para conforme Dicion√°rio de Dados\n",
    "colunas_map = {\n",
    "    'Event.Id': 'event_id',\n",
    "    'Investigation.Type': 'investigation_type',\n",
    "    'Accident.Number': 'accident_number',\n",
    "    'Event.Date': 'event_date',\n",
    "    'Location': 'location',\n",
    "    'Country': 'country',\n",
    "    'Latitude': 'latitude',\n",
    "    'Longitude': 'longitude',\n",
    "    'Airport.Code': 'airport_code',\n",
    "    'Airport.Name': 'airport_name',\n",
    "    'Injury.Severity': 'injury_severity_raw', # Mantemos a original temporariamente\n",
    "    'Aircraft.damage': 'aircraft_damage',\n",
    "    'Aircraft.Category': 'aircraft_category',\n",
    "    'Registration.Number': 'registration_number',\n",
    "    'Make': 'make',\n",
    "    'Model': 'model',\n",
    "    'Amateur.Built': 'amateur_built',\n",
    "    'Number.of.Engines': 'number_of_engines',\n",
    "    'Engine.Type': 'engine_type',\n",
    "    'Total.Fatal.Injuries': 'total_fatal_injuries',\n",
    "    'Total.Serious.Injuries': 'total_serious_injuries',\n",
    "    'Total.Minor.Injuries': 'total_minor_injuries',\n",
    "    'Total.Uninjured': 'total_uninjured',\n",
    "    'Weather.Condition': 'weather_condition',\n",
    "    'Broad.phase.of.flight': 'broad_phase_of_flight',\n",
    "    'Report.Status': 'report_status',\n",
    "    'Publication.Date': 'publication_date'\n",
    "}\n",
    "\n",
    "# Filtra colunas que realmente existem no CSV\n",
    "cols_to_use = [c for c in colunas_map.keys() if c in df.columns]\n",
    "df = df[cols_to_use].rename(columns=colunas_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d414d0f",
   "metadata": {},
   "source": [
    "## 5. Convers√£o e Limpeza de Tipos\n",
    "Corre√ß√£o de tipos de dados:\n",
    "1. **Datas:** Converter string para objeto datetime.\n",
    "2. **Num√©ricos:** Preencher Nulos (NaN) com 0 para colunas de v√≠timas.\n",
    "3. **Booleanos:** Converter 'Yes'/'No' para True/False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "be4b5f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Convertendo tipos de dados...\n",
      "   Convers√£o conclu√≠da.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ATA\\AppData\\Local\\Temp\\ipykernel_7460\\737331554.py:5: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['publication_date'] = pd.to_datetime(df['publication_date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConvertendo tipos de dados...\")\n",
    "\n",
    "# 1. Datas\n",
    "df['event_date'] = pd.to_datetime(df['event_date'], errors='coerce')\n",
    "df['publication_date'] = pd.to_datetime(df['publication_date'], errors='coerce')\n",
    "\n",
    "# 2. Num√©ricos (V√≠timas) - Regra: Nulo = 0\n",
    "cols_vitimas = ['total_fatal_injuries', 'total_serious_injuries', 'total_minor_injuries', 'total_uninjured']\n",
    "for col in cols_vitimas:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# 3. Num√©ricos (Motores) - Regra: Nulo = 1 (Assun√ß√£o conservadora ou manter nulo)\n",
    "df['number_of_engines'] = pd.to_numeric(df['number_of_engines'], errors='coerce').fillna(1).astype(int)\n",
    "\n",
    "# 4. Lat/Long\n",
    "df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')\n",
    "df['longitude'] = pd.to_numeric(df['longitude'], errors='coerce')\n",
    "\n",
    "print(\"   Convers√£o conclu√≠da.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b017c8",
   "metadata": {},
   "source": [
    "## 6. Engenharia de Atributos (Feature Engineering)\n",
    "Cria√ß√£o de novas colunas derivadas para facilitar a an√°lise no Power BI (Camada Gold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3a728431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Criando novas features...\n",
      "   Shape final ap√≥s engenharia: (88889, 31)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCriando novas features...\")\n",
    "\n",
    "# 6.1 Tratamento de Severidade Limpa\n",
    "df['injury_severity'] = df['injury_severity_raw'].apply(parse_severity)\n",
    "\n",
    "# 6.2 Extra√ß√£o de Ano e M√™s (Performance no Banco)\n",
    "df['year'] = df['event_date'].dt.year\n",
    "df['month'] = df['event_date'].dt.month\n",
    "\n",
    "# 6.3 Flag de Acidente Fatal (Para KPIs r√°pidos)\n",
    "df['is_fatal'] = df['total_fatal_injuries'] > 0\n",
    "\n",
    "# 6.4 Tratamento de Amateur Built (Booleano)\n",
    "# Remove espa√ßos e converte para booleano real\n",
    "df['amateur_built'] = df['amateur_built'].astype(str).str.lower().str.strip() == 'yes'\n",
    "\n",
    "# 6.5 Limpeza de Texto Final\n",
    "txt_cols = ['location', 'country', 'make', 'model', 'weather_condition']\n",
    "for col in txt_cols:\n",
    "    df[col] = df[col].apply(clean_text)\n",
    "\n",
    "print(f\"   Shape final ap√≥s engenharia: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e31c70",
   "metadata": {},
   "source": [
    "## 7. Popular Banco de Dados (Silver Layer)\n",
    "Utilizamos `psycopg2.extras.execute_batch` para inser√ß√£o em lote, garantindo alta performance mesmo com milhares de linhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a460897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando o Banco de Dados...\n",
      "Procurando arquivo em: c:\\Users\\ATA\\OneDrive\\Documentos\\Acidentes_aviao\\Data_Layer\\silver\\ddl.sql\n",
      "Arquivo ENCONTRADO!\n",
      "SUCESSO! Tabela 'aviao_silver' recriada usando o arquivo ddl.sql.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "\n",
    "print(\"Preparando o Banco de Dados...\")\n",
    "\n",
    "# CAMINHO CORRIGIDO: Sobe um n√≠vel (..), entra em Data_Layer, depois silver\n",
    "caminho_ddl = '../Data_Layer/silver/ddl.sql'\n",
    "\n",
    "print(f\"Procurando arquivo em: {os.path.abspath(caminho_ddl)}\")\n",
    "\n",
    "if os.path.exists(caminho_ddl):\n",
    "    print(f\"Arquivo ENCONTRADO!\")\n",
    "    \n",
    "    # Ler o conte√∫do do arquivo SQL\n",
    "    with open(caminho_ddl, 'r', encoding='utf-8') as f:\n",
    "        sql_oficial = f.read()\n",
    "\n",
    "    # Executar no Banco\n",
    "    try:\n",
    "        # Configura√ß√£o do banco (garantindo que usa db_aviao)\n",
    "        DB_CONFIG = {\n",
    "            'host': 'localhost',\n",
    "            'port': 5432,\n",
    "            'database': 'db_aviao',\n",
    "            'user': 'admin',\n",
    "            'password': 'admin'\n",
    "        }\n",
    "        \n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        cur.execute(sql_oficial)\n",
    "        conn.commit()\n",
    "        print(\"SUCESSO! Tabela 'aviao_silver' recriada usando o arquivo ddl.sql.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao executar o SQL: {e}\")\n",
    "    finally:\n",
    "        if 'conn' in locals(): conn.close()\n",
    "        \n",
    "else:\n",
    "    print(f\"ERRO CR√çTICO: O arquivo n√£o est√° l√°!\")\n",
    "    print(\"Confira se voc√™ salvou o 'ddl.sql' dentro de 'Acidentes_aviao/Data_Layer/silver/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5309a208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando colunas...\n",
      "Coluna 'schedule' n√£o encontrada. Criando vazia para evitar erros.\n",
      "Todas as colunas est√£o prontas. Pode rodar a pr√≥xima c√©lula!\n"
     ]
    }
   ],
   "source": [
    "# --- C√âLULA DE CORRE√á√ÉO ---\n",
    "# Garante que todas as colunas necess√°rias existam antes de salvar\n",
    "\n",
    "# Lista exata de colunas que o banco de dados espera\n",
    "colunas_esperadas = [\n",
    "    'event_id', 'investigation_type', 'accident_number', 'event_date', \n",
    "    'location', 'country', 'latitude', 'longitude', 'airport_code', 'airport_name', \n",
    "    'injury_severity', 'aircraft_damage', 'aircraft_category', 'registration_number', \n",
    "    'make', 'model', 'amateur_built', 'number_of_engines', 'engine_type', \n",
    "    'report_status', 'schedule', 'total_fatal_injuries', 'total_serious_injuries', \n",
    "    'total_minor_injuries', 'total_uninjured', 'weather_condition', \n",
    "    'broad_phase_of_flight', 'publication_date'\n",
    "]\n",
    "\n",
    "print(\"Verificando colunas...\")\n",
    "for col in colunas_esperadas:\n",
    "    if col not in df.columns:\n",
    "        print(f\"Coluna '{col}' n√£o encontrada. Criando vazia para evitar erros.\")\n",
    "        df[col] = None  # Cria a coluna preenchida com vazio\n",
    "    else:\n",
    "        # Garante que valores nulos (NaN) sejam convertidos para None (para o SQL aceitar)\n",
    "        df[col] = df[col].replace({np.nan: None})\n",
    "\n",
    "print(\"Todas as colunas est√£o prontas. Pode rodar a pr√≥xima c√©lula!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b56cb87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Removendo colunas extras...\n",
      "   Colunas antes: 32\n",
      "   Colunas depois: 28\n",
      "DataFrame limpo! Agora cont√©m apenas as colunas que o banco aceita.\n"
     ]
    }
   ],
   "source": [
    "# --- C√âLULA DE LIMPEZA FINAL ---\n",
    "# Remove colunas extras (como a _raw) que o banco n√£o aceita\n",
    "\n",
    "print(f\"üßπ Removendo colunas extras...\")\n",
    "print(f\"   Colunas antes: {len(df.columns)}\")\n",
    "\n",
    "# Mant√©m no DataFrame APENAS as colunas que est√£o na lista 'colunas_esperadas'\n",
    "# (Se a lista colunas_esperadas n√£o estiver definida, defina ela igual ao passo anterior)\n",
    "colunas_finais = [c for c in colunas_esperadas if c in df.columns]\n",
    "df = df[colunas_finais]\n",
    "\n",
    "print(f\"   Colunas depois: {len(df.columns)}\")\n",
    "print(\"DataFrame limpo! Agora cont√©m apenas as colunas que o banco aceita.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d3ea59a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando IDs duplicados...\n",
      "AVISO: Foram removidas 938 linhas duplicadas!\n",
      "   (Isso resolve o erro de 'duplicate key value')\n",
      " Total de linhas prontas para carga: 87951\n"
     ]
    }
   ],
   "source": [
    "# --- C√âLULA DE REMO√á√ÉO DE DUPLICATAS ---\n",
    "# O banco exige IDs √∫nicos. Vamos limpar duplicatas no CSV antes de enviar.\n",
    "\n",
    "print(f\"Verificando IDs duplicados...\")\n",
    "qtd_antes = len(df)\n",
    "\n",
    "# Remove linhas onde o 'event_id' √© igual, mantendo apenas a primeira apari√ß√£o\n",
    "df = df.drop_duplicates(subset=['event_id'], keep='first')\n",
    "\n",
    "qtd_depois = len(df)\n",
    "removidos = qtd_antes - qtd_depois\n",
    "\n",
    "if removidos > 0:\n",
    "    print(f\"AVISO: Foram removidas {removidos} linhas duplicadas!\")\n",
    "    print(f\"   (Isso resolve o erro de 'duplicate key value')\")\n",
    "else:\n",
    "    print(\" Nenhuma duplicata encontrada nos IDs.\")\n",
    "\n",
    "print(f\" Total de linhas prontas para carga: {qtd_depois}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4c73e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ajustando tamanho das strings (max 50 caracteres)...\n",
      "Textos longos foram truncados. Pronto para salvar!\n"
     ]
    }
   ],
   "source": [
    "# --- C√âLULA DE AJUSTE DE TAMANHO ---\n",
    "# O banco reclama se o texto for maior que o limite (50 caracteres).\n",
    "# Vamos cortar o excesso por seguran√ßa.\n",
    "\n",
    "# Lista de colunas definidas como VARCHAR(50) no  DDL\n",
    "cols_limite_50 = [\n",
    "    'event_id', 'investigation_type', 'accident_number', \n",
    "    'injury_severity', 'aircraft_damage', 'aircraft_category', \n",
    "    'registration_number', 'engine_type', 'schedule', \n",
    "    'weather_condition', 'report_status'\n",
    "]\n",
    "\n",
    "print(\" Ajustando tamanho das strings (max 50 caracteres)...\")\n",
    "\n",
    "for col in cols_limite_50:\n",
    "    if col in df.columns:\n",
    "        # Converte para string e corta nos primeiros 50 caracteres\n",
    "        # O 'str[:50]' pega do in√≠cio at√© o caractere 50\n",
    "        df[col] = df[col].astype(str).apply(lambda x: x[:50] if x and x != 'None' else None)\n",
    "\n",
    "print(\"Textos longos foram truncados. Pronto para salvar!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "24944d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validando coordenadas geogr√°ficas...\n",
      "Coordenadas inv√°lidas foram removidas.\n"
     ]
    }
   ],
   "source": [
    "# --- C√âLULA DE CORRE√á√ÉO DE COORDENADAS ---\n",
    "# O banco aceita no m√°ximo 4 d√≠gitos antes da v√≠rgula.\n",
    "# Vamos anular coordenadas imposs√≠veis (fora de -180 a 180).\n",
    "\n",
    "print(\"Validando coordenadas geogr√°ficas...\")\n",
    "\n",
    "def limpar_coordenada(valor, limite):\n",
    "    try:\n",
    "        if valor is None:\n",
    "            return None\n",
    "        num = float(valor)\n",
    "        # Se o n√∫mero for maior que o limite (ex: latitude > 90), vira None\n",
    "        if abs(num) > limite:\n",
    "            return None\n",
    "        return num\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "if 'latitude' in df.columns:\n",
    "    df['latitude'] = df['latitude'].apply(lambda x: limpar_coordenada(x, 90)) # Lat vai de -90 a 90\n",
    "\n",
    "if 'longitude' in df.columns:\n",
    "    df['longitude'] = df['longitude'].apply(lambda x: limpar_coordenada(x, 180)) # Long vai de -180 a 180\n",
    "\n",
    "print(\"Coordenadas inv√°lidas foram removidas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "88ca97d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salvando no PostgreSQL...\n",
      "   Conex√£o estabelecida.\n",
      "   Tabela truncada (limpa).\n",
      "   SUCESSO! 87951 registros inseridos na tabela aviao_silver.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSalvando no PostgreSQL...\")\n",
    "\n",
    "# 1. Conectar ao Banco\n",
    "try:\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    print(\"   Conex√£o estabelecida.\")\n",
    "    \n",
    "    # 2. Limpar tabela anterior (Full Refresh)\n",
    "    cur.execute(\"TRUNCATE TABLE aviao_silver;\")\n",
    "    conn.commit()\n",
    "    print(\"   Tabela truncada (limpa).\")\n",
    "\n",
    "    # 3. Preparar dados para inser√ß√£o\n",
    "    # Selecionamos as colunas na ordem exata da tabela do SQL\n",
    "    # Garantir que a ordem aqui bata com o CREATE TABLE do ddl.sql\n",
    "    \n",
    "    data_values = []\n",
    "    for idx, row in df.iterrows():\n",
    "        data_values.append((\n",
    "            str(row['event_id']),\n",
    "            row['investigation_type'],\n",
    "            row['accident_number'],\n",
    "            row['event_date'],\n",
    "            row['location'],\n",
    "            row['country'],\n",
    "            row['latitude'] if pd.notna(row['latitude']) else None,\n",
    "            row['longitude'] if pd.notna(row['longitude']) else None,\n",
    "            row['airport_code'],\n",
    "            row['airport_name'],\n",
    "            row['injury_severity'], # Usando a limpa\n",
    "            row['aircraft_damage'],\n",
    "            row['aircraft_category'],\n",
    "            row['registration_number'],\n",
    "            row['make'],\n",
    "            row['model'],\n",
    "            bool(row['amateur_built']),\n",
    "            int(row['number_of_engines']),\n",
    "            row['engine_type'],\n",
    "            row['report_status'], \n",
    "            row['schedule'],\n",
    "            # row['purpose_of_flight'],\n",
    "            # row['air_carrier'],\n",
    "            int(row['total_fatal_injuries']),\n",
    "            int(row['total_serious_injuries']),\n",
    "            int(row['total_minor_injuries']),\n",
    "            int(row['total_uninjured']),\n",
    "            row['weather_condition'],\n",
    "            row['broad_phase_of_flight'],\n",
    "            row['report_status'],\n",
    "            row['publication_date']\n",
    "        ))\n",
    "\n",
    "    # ATEN√á√ÉO: Ajuste este SQL para ter EXATAMENTE o mesmo n√∫mero de %s que colunas acima\n",
    "    # Vou fazer um SQL gen√©rico seguro baseado nas colunas principais do seu DDL anterior\n",
    "    insert_sql = \"\"\"\n",
    "        INSERT INTO aviao_silver (\n",
    "            event_id, investigation_type, accident_number, event_date, location, country,\n",
    "            latitude, longitude, airport_code, airport_name, injury_severity,\n",
    "            aircraft_damage, aircraft_category, registration_number, make, model,\n",
    "            amateur_built, number_of_engines, engine_type, far_description, schedule,\n",
    "            total_fatal_injuries, total_serious_injuries, total_minor_injuries,\n",
    "            total_uninjured, weather_condition, broad_phase_of_flight, report_status,\n",
    "            publication_date\n",
    "        ) VALUES (\n",
    "            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, \n",
    "            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n",
    "        )\n",
    "    \"\"\"\n",
    "    \n",
    "    # OBS: O loop acima gerou 30 campos, o SQL tem 29. \n",
    "    # Precisamos garantir que bata exatamente.\n",
    "    # Como o DDL pode variar, o jeito mais seguro √© usar Pandas to_sql\n",
    "    # Mas como o requisito √© o \"modelo Amazon\", vamos usar o engine do SQLAlchemy que √© mais robusto:\n",
    "    \n",
    "    engine = create_engine(DB_CONNECTION_STR)\n",
    "    df.to_sql('aviao_silver', engine, if_exists='append', index=False, method='multi', chunksize=1000)\n",
    "    \n",
    "    print(f\"   SUCESSO! {len(df)} registros inseridos na tabela aviao_silver.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro no Banco: {e}\")\n",
    "finally:\n",
    "    if 'conn' in locals(): conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e331e9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espiando os dados direto do Banco de Dados...\n",
      "Amostra dos dados na camada Silver:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>investigation_type</th>\n",
       "      <th>accident_number</th>\n",
       "      <th>event_date</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>airport_code</th>\n",
       "      <th>airport_name</th>\n",
       "      <th>injury_severity</th>\n",
       "      <th>aircraft_damage</th>\n",
       "      <th>aircraft_category</th>\n",
       "      <th>registration_number</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>amateur_built</th>\n",
       "      <th>number_of_engines</th>\n",
       "      <th>engine_type</th>\n",
       "      <th>far_description</th>\n",
       "      <th>schedule</th>\n",
       "      <th>purpose_of_flight</th>\n",
       "      <th>air_carrier</th>\n",
       "      <th>total_fatal_injuries</th>\n",
       "      <th>total_serious_injuries</th>\n",
       "      <th>total_minor_injuries</th>\n",
       "      <th>total_uninjured</th>\n",
       "      <th>weather_condition</th>\n",
       "      <th>broad_phase_of_flight</th>\n",
       "      <th>report_status</th>\n",
       "      <th>publication_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001218X45444</td>\n",
       "      <td>Accident</td>\n",
       "      <td>SEA87LA080</td>\n",
       "      <td>1948-10-24</td>\n",
       "      <td>MOOSE CREEK, ID</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fatal</td>\n",
       "      <td>Destroyed</td>\n",
       "      <td>None</td>\n",
       "      <td>NC6404</td>\n",
       "      <td>Stinson</td>\n",
       "      <td>108-3</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Cruise</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001218X45447</td>\n",
       "      <td>Accident</td>\n",
       "      <td>LAX94LA336</td>\n",
       "      <td>1962-07-19</td>\n",
       "      <td>BRIDGEPORT, CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fatal</td>\n",
       "      <td>Destroyed</td>\n",
       "      <td>None</td>\n",
       "      <td>N5069P</td>\n",
       "      <td>Piper</td>\n",
       "      <td>PA24-180</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>1996-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20061025X01555</td>\n",
       "      <td>Accident</td>\n",
       "      <td>NYC07LA005</td>\n",
       "      <td>1974-08-30</td>\n",
       "      <td>Saltville, VA</td>\n",
       "      <td>United States</td>\n",
       "      <td>36.922223</td>\n",
       "      <td>-81.878056</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fatal</td>\n",
       "      <td>Destroyed</td>\n",
       "      <td>None</td>\n",
       "      <td>N5142R</td>\n",
       "      <td>Cessna</td>\n",
       "      <td>172M</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IMC</td>\n",
       "      <td>Cruise</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>2007-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001218X45448</td>\n",
       "      <td>Accident</td>\n",
       "      <td>LAX96LA321</td>\n",
       "      <td>1977-06-19</td>\n",
       "      <td>EUREKA, CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fatal</td>\n",
       "      <td>Destroyed</td>\n",
       "      <td>None</td>\n",
       "      <td>N1168J</td>\n",
       "      <td>Rockwell</td>\n",
       "      <td>112</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IMC</td>\n",
       "      <td>Cruise</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>2000-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20041105X01764</td>\n",
       "      <td>Accident</td>\n",
       "      <td>CHI79FA064</td>\n",
       "      <td>1979-08-02</td>\n",
       "      <td>Canton, OH</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fatal</td>\n",
       "      <td>Destroyed</td>\n",
       "      <td>None</td>\n",
       "      <td>N15NY</td>\n",
       "      <td>Cessna</td>\n",
       "      <td>501</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VMC</td>\n",
       "      <td>Approach</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>1980-04-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         event_id investigation_type accident_number  event_date  \\\n",
       "0  20001218X45444           Accident      SEA87LA080  1948-10-24   \n",
       "1  20001218X45447           Accident      LAX94LA336  1962-07-19   \n",
       "2  20061025X01555           Accident      NYC07LA005  1974-08-30   \n",
       "3  20001218X45448           Accident      LAX96LA321  1977-06-19   \n",
       "4  20041105X01764           Accident      CHI79FA064  1979-08-02   \n",
       "\n",
       "          location        country   latitude  longitude airport_code  \\\n",
       "0  MOOSE CREEK, ID  United States        NaN        NaN         None   \n",
       "1   BRIDGEPORT, CA  United States        NaN        NaN         None   \n",
       "2    Saltville, VA  United States  36.922223 -81.878056         None   \n",
       "3       EUREKA, CA  United States        NaN        NaN         None   \n",
       "4       Canton, OH  United States        NaN        NaN         None   \n",
       "\n",
       "  airport_name injury_severity aircraft_damage aircraft_category  \\\n",
       "0         None           Fatal       Destroyed              None   \n",
       "1         None           Fatal       Destroyed              None   \n",
       "2         None           Fatal       Destroyed              None   \n",
       "3         None           Fatal       Destroyed              None   \n",
       "4         None           Fatal       Destroyed              None   \n",
       "\n",
       "  registration_number      make     model  amateur_built  number_of_engines  \\\n",
       "0              NC6404   Stinson     108-3          False                  1   \n",
       "1              N5069P     Piper  PA24-180          False                  1   \n",
       "2              N5142R    Cessna      172M          False                  1   \n",
       "3              N1168J  Rockwell       112          False                  1   \n",
       "4               N15NY    Cessna       501          False                  1   \n",
       "\n",
       "     engine_type far_description schedule purpose_of_flight air_carrier  \\\n",
       "0  Reciprocating            None     None              None        None   \n",
       "1  Reciprocating            None     None              None        None   \n",
       "2  Reciprocating            None     None              None        None   \n",
       "3  Reciprocating            None     None              None        None   \n",
       "4           None            None     None              None        None   \n",
       "\n",
       "   total_fatal_injuries  total_serious_injuries  total_minor_injuries  \\\n",
       "0                     2                       0                     0   \n",
       "1                     4                       0                     0   \n",
       "2                     3                       0                     0   \n",
       "3                     2                       0                     0   \n",
       "4                     1                       2                     0   \n",
       "\n",
       "   total_uninjured weather_condition broad_phase_of_flight   report_status  \\\n",
       "0                0               UNK                Cruise  Probable Cause   \n",
       "1                0               UNK               Unknown  Probable Cause   \n",
       "2                0               IMC                Cruise  Probable Cause   \n",
       "3                0               IMC                Cruise  Probable Cause   \n",
       "4                0               VMC              Approach  Probable Cause   \n",
       "\n",
       "  publication_date  \n",
       "0             None  \n",
       "1       1996-09-19  \n",
       "2       2007-02-26  \n",
       "3       2000-09-12  \n",
       "4       1980-04-16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- C√âLULA DE VALIDA√á√ÉO FINAL ---\n",
    "print(\"Espiando os dados direto do Banco de Dados...\")\n",
    "\n",
    "# L√™ 5 linhas da tabela rec√©m-criada\n",
    "try:\n",
    "    df_check = pd.read_sql(\"SELECT * FROM aviao_silver LIMIT 5\", engine)\n",
    "    print(\"Amostra dos dados na camada Silver:\")\n",
    "    display(df_check) # Se n√£o funcionar display, use print(df_check)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
